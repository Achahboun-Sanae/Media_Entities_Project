## üìå Projet SD : Extraction et Visualisation des Entit√©s M√©diatiques Marocaines
Ce projet vise √† extraire et visualiser des entit√©s m√©diatiques marocaines √† partir de sites d‚Äôactualit√©s.

üîπ **Cette premi√®re √©tape du projet** est consacr√©e √† **la collecte et au stockage des articles**. Elle comprend les phases suivantes :

- **Collecte des URLs des articles**.
- **Scraping du contenu des articles**.
- **Stockage structur√© dans MongoDB**.
- **√âlimination des doublons**.
  
Les prochaines √©tapes incluront **le traitement NLP**, **la structuration des donn√©es** et **la visualisation des r√©sultats**.

---

## üîç Fonctionnalit√©s  

### üìå 1. Collecte des URLs des articles  
- Extraction des liens des articles √† partir des pages de cat√©gories des sites d'actualit√©s marocains.  
- Les cat√©gories concern√©es incluent, par exemple, la culture et d'autres sections pertinentes du site.


### üìå 2. Scraping du contenu des articles  
- Extraction des informations cl√©s des articles :  
  - **Titre**  
  - **Auteur**  
  - **Contenu**  
  - **Date de publication**  
  - **Cat√©gorie**  

- V√©rification et nettoyage des donn√©es avant stockage. 


### üìå 3. Stockage des donn√©es 
   - Les articles collect√©s et analys√©s sont stock√©s dans une base de donn√©es **MongoDB**, ce qui permet une gestion flexible et √©volutive des donn√©es.
   - **MongoDB Atlas** est utilis√© pour offrir un acc√®s s√©curis√© et distant √† tous les membres de l'√©quipe, permettant une collaboration efficace et un acc√®s aux donn√©es depuis n'importe o√π.
   - La base de donn√©es permet de g√©rer efficacement les articles collect√©s et de garantir des performances √©lev√©es lors de l'acc√®s aux informations.
   - Les articles collect√©s sont stock√©s dans **MongoDB Atlas**, avec la structure suivante :  

```python
article_data = {
    "url": url,
    "titre": titre,
    "auteur": auteur,
    "contenu": contenu,
    "source": source,  # o√π 'source' peut √™tre "ChoufTv", "Hespress", ou "Akhbarona", ou "Le360" 
    "categorie": categorie,
    "date": date_publication
}
  ```

### üìå 4. Gestion des doublons
   - Avant d'ajouter chaque article dans la base de donn√©es, une v√©rification est effectu√©e pour √©viter les doublons, assurant ainsi une base de donn√©es propre et sans redondance.

---

## ‚öôÔ∏è Technologies Utilis√©es

- **Python** : Langage de programmation utilis√© pour le scraping et le traitement des donn√©es.
- **BeautifulSoup** : Biblioth√®que pour l'analyse et l'extraction des informations des pages web HTML.
- **Requests** : Biblioth√®que pour effectuer des requ√™tes HTTP et r√©cup√©rer les pages des articles.
- **MongoDB & MongoDB Atlas** : Base de donn√©es NoSQL utilis√©e pour stocker les articles collect√©s.
- **MongoDB Atlas** : permet un acc√®s distant s√©curis√© pour tous les membres de l'√©quipe.

## Description de la deuxieme Etape : 

Ce projet se concentre sur l'application du traitement automatique du langage naturel (NLP) pour nettoyer et structurer des donn√©es textuelles. Il utilise des techniques avanc√©es telles que la **tokenisation**, la **lemmatisation**, et la **reconnaissance d'entit√©s nomm√©es (NER)** √† l'aide de mod√®les NLP comme SpaCy, BERT et Stanford NLP.

### Fonctionnalit√©s Cl√©s

- **Traitement NLP** : 
  - **Nettoyage des textes** : Suppression des ponctuations et des stopwords.
  - **Tokenisation** : Division des textes en mots ou tokens individuels.
  - **Lemmatisation** : R√©duction des mots √† leur forme de base.
  - **Application de NER** : Identification des entit√©s telles que les personnes, lieux, organisations et √©v√©nements.

- **Structuration des donn√©es** : 
  - **Enregistrement dans une base SQL (PostgreSQL)** : Stockage structur√© des entit√©s et relations pour faciliter les requ√™tes.
  - **Enregistrement dans une base graphique (Neo4j)** : Mod√©lisation des relations complexes entre entit√©s.

- **Fonctionnalit√©s G√©n√©rales du Syst√®me** :
  - **Extraction des entit√©s** : Identification automatique des noms de personnes, lieux, organisations et √©v√©nements.
  - **Stockage structur√©** : Organisation des donn√©es en bases relationnelles et graphiques.
  - **Analyse des relations** : Etablissement des liens entre les entit√©s d√©tect√©es.
---

### Technologies Utilis√©es

- **SpaCy** : Pour la tokenisation et la reconnaissance d'entit√©s.
- **BERT** : Pour des analyses plus avanc√©es du langage.
- **nltk** : Biblioth√®que de traitement du langage naturel en Python, utilis√©e pour la tokenisation, la lemmatisation, l'analyse syntaxique et la reconnaissance d'entit√©s nomm√©es.
- **Stanza** : Biblioth√®que NLP de Stanford offrant des mod√®les pr√©-entra√Æn√©s pour plusieurs langues, utilis√©e pour l'analyse morphologique, syntaxique et la reconnaissance d'entit√©s nomm√©es.
- **transformers** : Biblioth√®que de Hugging Face permettant d'utiliser des mod√®les de deep learning pour le NLP, 
- **PostgreSQL** : Pour le stockage relationnel.
- **Supbase** : Pour le stockage relationnelAlternative open-source √† Firebase, bas√©e sur PostgreSQL, offrant base de donn√©es, authentification, stockage et fonctions serverless..
- **Neo4j** : Pour le stockage graphique.

---
## üìå Auteur
- üõ† Projet r√©alis√© par une √©quipe de 4 personnes
- **Ann√©e** : 2025
